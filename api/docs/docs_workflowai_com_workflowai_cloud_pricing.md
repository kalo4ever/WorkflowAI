WorkflowAI Cloud is a pay-as-you-go infrastructure, similar to Amazon Web Services. There is no fixed cost, minimum spend, or annual commitment. You don't need to talk to sales to get started.

## [Direct link to heading](https://docs.workflowai.com/workflowai-cloud/pricing\#costs)    Costs

WorkflowAI Cloud charges only for:

- the tokens generated by your AI agents (per token generated)

- the tools used by your AI agents (per tool used)


We **don't** charge by:

- GB of data stored

- number of AI agents

- number of members in your organization

- bandwidth or CPU usage


## [Direct link to heading](https://docs.workflowai.com/workflowai-cloud/pricing\#price-match-guarantee)    Price match guarantee

For any AI provider, we offer a price-match guarantee: WorkflowAI Cloud **charges the same per token price** than the AI provider you're using. Currently, we support models from OpenAI, Anthropic, Google, Mistral, LLAMA (provided by [FireworksAI](https://fireworks.ai/)).

If you have credits with Amazon, Google, or Azure, you can also continue to use them via WorkflowAI Cloud, [by providing your own API keys](https://github.com/WorkflowAI/documentation/blob/main/docs/cloud/features/deployments.md#using-your-own-ai-providers-api).

## [Direct link to heading](https://docs.workflowai.com/workflowai-cloud/pricing\#what-is-workflowai-cloud-business-model)    What is WorkflowAI Cloud business model?

We are making our margin by buying LLMs tokens in bulk, with a discount, and then reselling them to you at public price.

Thinking from first principles, the cost of inference is mostly GPU and electricity, not tokens. When you buy tokens from a LLM provider, effectively you are paying for the electricity and GPU cost. But renting a GPU makes only sense if you can utilize the GPU at maximum capacity, all the time.

[PreviousIntroduction](https://docs.workflowai.com/workflowai-cloud/introduction) [NextReliability](https://docs.workflowai.com/workflowai-cloud/reliability)

Last updated 1 month ago

Was this helpful?

* * *